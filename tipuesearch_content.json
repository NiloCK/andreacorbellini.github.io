{"pages":[{"tags":"pages","url":"http://andrea.corbellini.name/about/","text":"I'm a software developer with a passion for the web and the cloud. Over the years, I've had the opportunity to work with a large set of technologies, in many different fields. This has let me gain a wide and deep experience. Nowadays, I enjoy designing cloud and cloud-based services with focus on security, quality, scalability and continuous delivery. I like delivering high quality software in time. I also enjoy improving and discussing development methodologies and I'm a fan of Agile (although I do not see it as a set of unbreakable rules, but rather as the formalization of a culture based on solid principles). I like challenges and always try to experiment new technologies and approaches to problems. When I'm not working, I'm usually some feet underwater. If you want to get in touch with me: Email Twitter StackOverflow Careers LinkedIn","title":"About"},{"tags":"misc","url":"http://andrea.corbellini.name/2015/09/22/cookie-law/","text":"For a few years now, every first of April I hoped to read between the news something on the lines of \"the cookie law was a joke, sorry for that\". You know, bureaucracy is slow, and it's reasonable to think that it takes time for them to reveal jokes. Yet, many firsts of April have passed, and no such announcement has been made. Many missed opportunities for Europe to show their love for progress and their competence with the web. Being compliant with the EU cookie law is hard to do. It's not just a matter of showing a boring banner, it's a matter of defacing your web pages, writing long privacy policies that nobody will read, implementing ways to prevent certain cookies from being set. The truth is: if you, as a webmaster, want to avoid wasting time and avoid headaches, you just have to avoid cookies. This is what I have done with most websites I maintain: I have removed all analytics, all social sharing buttons, all YouTube videos, all comments . This was a sad thing to do, but it was the only thing I could do: I maintain websites for free mainly as a favor for friends and no-profits I'm involved with — it's not my day job. Also, I do not want other people being sued because of mistakes from my side: cookies may be set in the most unexpected situations and disabling every feature that could potentially set them seems the safest choice. The only exception is this blog. Here, I use cookies for Google Analytics, for social sharing buttons and for Disqus. I may live without Google Analytics (even though it gives useful insights, such as performance statistics and tips), but I can't really remove social buttons and Disqus: this is a blog and it wouldn't make any sense to remove social features and comments. Being compliant with the EU cookie law has been on my todo list for a while, and I never found the time (nor the desire) to look into it. Today I did. I spent a few hours of my time to discover that Google Analytics is \"OK\" (in the sense that I do not have to display an ugly banner, nor have to ask for explicit permission from the user before setting the cookies) and to discover that social buttons and Disqus are \"bad\" (in the sense that I have to display a banner and ask for explicit consent from the user before setting the cookies). In the end, the only service that I could remove is the less problematic service. As I said, I really do not want to remove social buttons, Disqus or whatever third-party content I'll want to display in the future. Therefore, in order to comply with the cookie law, I'm forced to write code, write a privacy policy, waste another bunch of hours of my time. But not today, as I've already had enough sense of sadness and impotence. At least for now, I guess that the EU cookie law compliance will stay on my todo list for some more time. Probably if I worked on compliance instead of writing this rant, I could have already finished (but then what's the point of having a blog if you don't blog?) The cookie law wants to be \"on the side of the users,\" and it is based on noble principles: it wants users to be well-informed about how their data is used and by whom. However, as it is today, it's against both users and webmasters. Webmasters have to lose their time working on compliance, and users receive a degraded experience due to silly regulations. I'd like to do what Silktide did : actively protesting against the law, but I wouldn't be so happy if I were sued. I'd like to read \"the cookie law was a joke\" in the news, but I'm starting to believe that it's not going to happen any time soon. It seems that accepting the sadness of the reality is the only option I'm left with. End of rant, let's move on.","title":"When bureaucracy hits the web: the cookie law"},{"tags":"misc","url":"http://andrea.corbellini.name/2015/08/02/hello-pelican/","text":"Today I switched from WordPress.com to Pelican and GitHub Pages . First off, let me say: almost all URLs that were previously working should still work. Only the feed URLs are broken, and this is not something I can fix. If you were following my blog via a feed reader, you should update to the new feed. Sorry for the inconvenience. Having said that, I'd like to share with you the motivation that made me move and the details of the migration. The bad things of WordPress Now, this doesn't want to be a rant, so I'll be pretty concise. WordPress, the content management system, is an excellent platform for blogging. Easy to start with, easy to maintain, easy to use. WordPress.com makes things even easier. It also comes with many useful features, like comments and social networks integration. The problem is: you can't customize things or add features without paying. Of course, this is business, and I do not want to discuss business decisions made at WordPress.com. Not only that, but I could live fine with most of the major limitations. Also, I was perfectly conscious of this kind of problems with WordPress.com when I started (after all, this is not the first blog I started ). I actually become upset of WordPress.com when writing the series of blog posts about Elliptic Curve Cryptography . When writing these articles, I spent a lot of time employing workarounds to overcome WordPress.com limitations. Being used to Vim and its advanced features, I also found the editors (both the old and the new one) as a great obstacle for getting things done quickly. I do not want to enter the details of the problems I'm referring to, what matters is that, eventually, I gave up and I realized it was time to move on and seek for an alternative. Why Pelican Pelican is a static site generator. I've always thought that a static site had too many limitations for me. But while seeking an alternative to WordPress.com, I realized that many of those limitations were not affecting me in any way. Actually, with a static site I can do everything I want: edit my articles with Vim, render my equations with MathJax, customize my theme, version control my content, write scripts to post process my content. The only bad thing about Pelican is that it does not come with any theme I truly like. I decided to make my own. I'm not entirely satisfied with it, as I feel it is too \"anonymous\", but I believe it is fully responsive, fast, readable and offers all the features I want. Perhaps I'll tweak it a little more to make it more \"personal\". Setting up Pelican and migrating everything required some time, but at least this time I worked on true solutions, not on ugly hacks and workarounds like I did with WordPress. This implies that when writing articles I will be able to focus more on content than other details. Why not other static site generators In short: Pelican is written in Python and to my eyes it looked better than the other Python static site generators. I'll be honest and say that I did not truly evaluate all of the alternatives: I knew list.org switched to Pelican and that made me try Pelican before all other solutions. Conclusion In the end I decided to leave WordPress for Pelican hosted on GitHub Pages. I'm pretty satisfied with the result I got. The nature of GitHub Pages prevents me from using HTTP redirects (and therefore the old feed links are broken), however in exchange I've got much more freedom, and this is what matters to me.","title":"Hello Pelican!"},{"tags":"cryptography","url":"http://andrea.corbellini.name/2015/06/16/lets-encrypt-is-going-to-start-soon/","text":"Let's Encrypt (the free, automated and open certificate authority) has just announced its launch schedule . According to it, certificates will be released to the public starting from the week of September 14, 2015 . Their intermediate certificates, which were generated a few days ago , will be signed by IdenTrust . What this means is that if you browse a web page secured by Let's Encrypt, you won't get any scary message, but the usual green lock. You will see this... ... not this. In case you are curious: the root certificate is a 4096-bit RSA key, the two intermediate certificates are both 2048-bit RSA keys. But they are also planning to generate ECDSA keys later this year as well. Technical aspects aside, this will be a great opportunity for the entire web. As I have already written , I always dreamed of an encrypted web, and I truly believe that Let's Encrypt — or at least its approach to the problem — is the way to go. So, will you get a Let's Encrypt certificate when the time comes? I will do. Not for this blog (I can't put a certificate without paying), but for other websites I manage. Perhaps I'll also show a \"Proudly secured by Let's Encrypt\" badge.","title":"Let's Encrypt is going to start soon"},{"tags":"cryptography","url":"http://andrea.corbellini.name/2015/06/08/elliptic-curve-cryptography-breaking-security-and-a-comparison-with-rsa/","text":"This post is the fourth and last in the series ECC: a gentle introduction . In the last post we have seen two algorithms, ECDH and ECDSA, and we have seen how the discrete logarithm problem for elliptic curves plays an important role for their security. But, if you remember, we said that we have no mathematical proofs for the complexity of the discrete logarithm problem: we believe it to be \"hard\", but we can't be sure. In the first part of this post, we'll try to get an idea of how \"hard\" it is in practice with today's techniques. Then, in the second part, we will try to answer the question: why do we need elliptic curve cryptography if RSA (and the other cryptosystems based on modular arithmetic) work well? Breaking the discrete logarithm problem We will now see the two most efficient algorithms for computing discrete logarithms on elliptic curve: the baby-step, giant-step algorithm, and Pollard's rho method. Before starting, as a reminder, here is what the discrete logarithm problem is about: given two points $P$ and $Q$ find out the integer $x$ that satisfies the equation $Q = xP$ . The points belong to a subgroup of an elliptic curve, which has a base point $G$ and which order is $n$. Baby-step, giant-step Before entering the details of the algorithm, a quick consideration: we can always write any integer $x$ as $x = am + b$ , where $a$, $m$ and $b$ are three arbitrary integers. For example, we can write $10 = 2 \\cdot 3 + 4$. With this in mind, we can rewrite the equation for the discrete logarithm problem as follows: $$\\begin{array}{rl} Q & = xP \\\\ Q & = (am + b) P \\\\ Q & = am P + b P \\\\ Q - am P & = b P \\end{array}$$ The baby-step giant-step is a \"meet in the middle\" algorithm. Contrary to the brute-force attack (which forces us to calculate all the points $xP$ for every $x$ until we find $Q$), we will calculate \"few\" values for $bP$ and \"few\" values for $Q - amP$ until we find a correspondence. The algorithm works as follows: Calculate $m = \\left\\lceil{\\sqrt{n}}\\right\\rceil$ For every $b$ in ${0, \\dots, m}$, calculate $bP$ and store the results in a hash table. For every $a$ in ${0, \\dots, m}$: calculate $amP$; calculate $Q - amP$; check the hash table and look if there exist a point $bP$ such that $Q - amP = bP$; if such point exists, then we have found $x = am + b$. As you can see, initially we calculate the points $bP$ with little (i.e. \"baby\" ) increments for the coefficient $b$ ($1P$, $2P$, $3P$, ...). Then, in the second part of the algorithm, we calculate the points $amP$ with huge (i.e. \"giant\" ) increments for $am$ ($1mP$, $2mP$, $3mP$, ..., where $m$ is a huge number). The baby-step, giant-step algorithm: initially we calculate few points via small steps and store them in a hash table. Then we perform the giant steps and compare the new points with the points in the hash table. Once a match is found, calculating the discrete logarithm is a matter of rearranging terms. To understand why this algorithm works, forget for a moment that the points $bP$ are cached and take the equation $Q = amP + bP$. Consider what follows: When $a = 0$ we are checking whether $Q$ is equal to $bP$, where $b$ is one of the integers from 0 to $m$. This way, we are comparing $Q$ against all points from $0P$ to $mP$. When $a = 1$ we are checking whether $Q$ is equal to $mP + bP$. We are comparing $Q$ against all points from $mP$ to $2mP$. When $a = 2$ we are comparing $Q$ against all the points from $2mP$ to $3mP$. ... When $a = m - 1$, we are comparing $Q$ against all points from $(m - 1)mP$ to $m&#94;2 P = nP$. In conclusion, we are checking all points from $0P$ to $nP$ (that is, all the possible points) performing at most $2m$ additions and multiplications (exactly $m$ for the baby steps, at most $m$ for the giant steps). If you consider that a lookup on a hash table takes $O(1)$ time, it's easy to see that this algorithm has both time and space complexity $O(\\sqrt{n})$ (or $O(2&#94;{k / 2})$ if you consider the bit length). It's still exponential time, but much better than a brute-force attack. Baby-step giant-step in practice It may make sense to see what the complexity $O(\\sqrt{n})$ means in practice. Let's take a standardized curve: prime192v1 (aka secp192r1 , ansiX9p192r1 ). This curve has order $n$ = 0xffffffff ffffffff ffffffff 99def836 146bc9b1 b4d22831. The square root of $n$ is approximately 7.922816251426434 · 10 28 (almost eighty octilions ). Now imagine storing $\\sqrt{n}$ points in a hash table. Suppose that each point requires exactly 32 bytes: our hash table would need approximately 2.5 · 10 30 bytes of memory . Looking on the web , it seems that the total world storage capacity is in the order of the zettabyte (10 21 bytes). This is almost ten orders of magnitude lower than the memory required by our hash table! Even if our points took 1 byte each, we would be still very far from being able to store all of them. This is impressive, and is even more impressive if you consider that prime192v1 is one of the curves with the lowest order. The order of secp521r1 (another standard curve from NIST) is approximately 6.9 · 10 156 ! Playing with baby-step giant-step I made a Python script that computes discrete logarithms using the baby-step giant-step algorithm. Obviously it only works with curves with small orders: don't try it with secp521r1 , unless you want to receive a MemoryError . It should produce an output like this: Curve : y &#94; 2 = ( x &#94; 3 + 1 x - 1 ) mod 10177 Curve order : 10331 p = ( 0x1 , 0x1 ) q = ( 0x1a28 , 0x8fb ) 325 * p = q log ( p , q ) = 325 Took 105 steps Pollard's ρ Pollard's rho is another algorithm for computing discrete logarithms. It has the same asymptotic time complexity $O(\\sqrt{n})$ of the baby-step giant-step algorithm, but its space complexity is just $O(1)$. If baby-step giant-step can't solve discrete logarithms because of the huge memory requirements, will Pollard's rho make it? Let's see... First of all, another reminder of the discrete logarithm problem: given $P$ and $Q$ find $x$ such that $Q = xP$. With Pollard's rho, we will solve a sightly different problem: given $P$ and $Q$, find the integers $a$, $b$, $A$ and $B$ such that $aP + bQ = AP + BQ$ . Once the four integers are found, we can use the equation $Q = xP$ to find out $x$: $$\\begin{array}{rl} aP + bQ & = AP + BQ \\\\ aP + bxP & = AP + BxP \\\\ (a + bx) P & = (A + Bx) P \\\\ (a - A) P & = (B - b) xP \\end{array}$$ Now we can get rid of $P$. But before doing so, remember that our subgroup is cyclic with order $n$, therefore the coefficients used in point multiplication are modulo $n$: $$\\begin{array}{rl} a - A & \\equiv (B - b) x \\pmod{n} \\\\ x & = (a - A)(B - b)&#94;{-1} \\bmod{n} \\end{array}$$ The principle of operation of Pollard's rho is simple: we define a pseudo-random sequence of $(a, b)$ pairs . This sequence of pairs can be used to generate the sequence of points $aP + bQ$. Because both $P$ and $Q$ are elements of the same cyclic subgroup, the sequence of points $aP + bQ$ is cyclic too . This means that if walk our pseudo-random sequence of $(a, b)$ pairs, sooner or later we will detect a cycle. That is: we will find a pair $(a, b)$ and another distinct pair $(A, B)$ such that $aP + bQ = AP + BQ$ . Same points, distinct pairs: we can apply the equation above to find the logarithm. The problem is: how do we detect the cycle in an efficient way? Tortoise and Hare In order to detect our cycle, we could try all the possible values for $a$ and $b$ using a pairing function , but given that there are $n&#94;2$ such pairs, our algorithm would be $O(n&#94;2)$, much worse than a brute-force attack. But there exist a faster method: the tortoise and hare algorithm (also known as Floyd's cycle-finding algorithm). The picture below shows the principle of operation of the tortoise and hare method, which is at the core of Pollard's rho. We have the curve $y&#94;2 \\equiv x&#94;3 + 2x + 3 \\pmod{97}$ and the points $P = (3, 6)$ and $Q = (80, 87)$. The points belong to a cyclic subgroup of order 5. We walk a sequence of pairs at different speeds until we find two different pairs $(a, b)$ and $(A, B)$ that produce the same point. In this case, we have found the pairs $(3, 3)$ and $(2, 0)$ that allow us to calculate the logarithm as $x = (3 - 2)(0 - 3)&#94;{-1} \\bmod{5} = 3$. And in fact we correctly have $Q = 3P$. Basically, we take our pseudo-random sequence of $(a, b)$ pairs, together with the corresponding sequence of $aP + bQ$ points. The sequence of $(a, b)$ pairs may or may not be cyclic, but the sequence of point is, because both $P$ and $Q$ were generated from the same base point, and from the properties of subgroups we know that we can't \"escape\" from the subgroup using just scalar multiplication and addition. Now we take our two pets, the tortoise and the hare, and make them walk our sequence from left to right. The tortoise (the green spot in the picture) is slow and reads each point one by one ; the hare (represented in red) is fast and skips a point at every step . After some time both the tortoise and the hare will have found the same point, but with different coefficient pairs. Or, to express that with equations, the tortoise will have found a pair $(a, b)$ and the hare will have found a pair $(A, B)$ such that $aP + bQ = AP + BQ$. If our random sequence is defined through an algorithm (as opposed to being stored statically), it's easy to see how this principle of operation requires just $O(\\log n)$ space . Calculating the asymptotic time complexity is not that easy, but we can build a probabilistic proof that shows how the time complexity is $O(\\sqrt{n})$ , as we have already said. Playing with Pollard's ρ I've built a Python script that computes discrete logarithms using Pollard's rho. It is not the implementation of the original Pollard's rho, but a slight variation of it (I've used a more efficient method for generating the pseudo-random sequence of pairs). The script contains some useful comments, so read it if you are interested in the details of the algorithm. This script, like the baby-step giant-step one, works on a tiny curve, and produces the same kind of output. Pollard's ρ in practice We said that baby-step giant-step can't be used in practice, because of the huge memory requirements. Pollard's rho, on the other hand, requires very few memory. So, how practical is it? Certicom launched a challenge in 1998 to compute discrete logarithms on elliptic curves with bit lengths ranging from 109 to 359. As of today, only 109-bit long curves have been successfully broken. The latest successful attempt was made in 2004. Quoting Wikipedia : The prize was awarded on 8 April 2004 to a group of about 2600 people represented by Chris Monico. They also used a version of a parallelized Pollard rho method, taking 17 months of calendar time. As we have already said, prime192v1 is one of the \"smallest\" elliptic curves. We also said that Pollard's rho has $O(\\sqrt{n})$ time complexity. If we used the same technique as Chris Monico (the same algorithm, on the same hardware, with the same number of machines), how much would it take to compute a logarithm on prime192v1 ? $$17\\ \\text{months}\\ \\times \\frac{\\sqrt{2&#94;{192}}}{\\sqrt{2&#94;{109}}} \\approx 5 \\cdot 10&#94;{13}\\ \\text{months}$$ This number is pretty self-explanatory and gives a clear idea of how hard it can be to break a discrete logarithm using such techniques. Pollard's ρ vs Baby-step giant-step I decided to put the baby-step giant-step script and the Pollard's rho script together with a brute-force script into a fourth script to compare their performances. This fourth script computes all the logarithms for all the points on the \"tiny\" curve using different algorithms and reports how much time it did take: Curve order: 10331 Using bruteforce Computing all logarithms: 100.00% done Took 2m 31s (5193 steps on average) Using babygiantstep Computing all logarithms: 100.00% done Took 0m 6s (152 steps on average) Using pollardsrho Computing all logarithms: 100.00% done Took 0m 21s (138 steps on average) As we could expect, the brute-force method is tremendously slow if compared to the others two. Baby-step giant-step is the faster, while Pollard's rho is more than three times slower than baby-step giant-step (although it uses far less memory and fewer number of steps on average). Also look at the number of steps: brute force used 5193 steps on average for computing each logarithm. 5193 is very near to 10331 / 2 (half the curve order). Baby-step giant-steps and Pollard's rho used 152 steps and 138 steps respectively, two numbers very close to the square root of 10331 (101.64). Final consideration While discussing these algorithms, I have presented many numbers. It's important to be cautious when reading them: algorithms can be greatly optimized in many ways. Hardware can improve. Specialized hardware can be built. The fact that an approach today seems impractical, does not imply that the approach can't be improved. It also does not imply that other, better approaches exist (remember, once again, that we have no proofs for the complexity of the discrete logarithm problem). Shor's algorithm If today's techniques are unsuitable, what about tomorrow's techniques? Well, things are a bit more worrisome: there exist a quantum algorithm capable of computing discrete logarithms in polynomial time: Shor's algorithm , which has time complexity $O((\\log n)&#94;3)$ and space complexity $O(\\log n)$. The efficiency of quantum algorithms stands in state superposition. On classical computers, the memory cells (i.e. the bits) may be either 1 or 0. There are no intermediate states between the two. On the other hand, the memory cells of quantum computers (known as qubits) instead are subject to the uncertainty principle: they do not have a truly defined state until they are measured. State superposition does not mean that each qubit may be 0 and 1 at the same time (as it is often said on the web), it means that when we measure the qubit, we have a certain probability of observing 0, and another probability of observing 1. Quantum algorithms work by modifying the probability of each qubit. This peculiarity implies that with a limited number of qubits, we can deal with lots of possible inputs at the same time. So, for example, we can tell a quantum computer that there's a number $x$ uniformly distributed between 0 and $n - 1$. This requires just $\\log n$ qubits instead of $n \\log n$ bits. Then, we can tell the quantum computer to perform scalar multiplication $xP$. This will result in the superposition of states given by all the points from $0P$ to $(n - 1)P$ — that is, if we measured our qubits now, we would obtain one of the points from $0P$ to $(n - 1)P$ with probability $1 / n$. This was to give you an idea of how powerful state superposition is. Shor's algorithm does not work exactly this way, it is actually more complicated. What makes it complicated is that, while we can \"simulate\" $n$ states at the same time, at some point we have to reduce these many states to just a few ones, because we want as output a single answer, not many (i.e. we want to know one single logarithm, not many probable wrong logarithms). ECC and RSA Now let's forget about quantum computing, which is still far from being a serious problem. The question I'll answer now is: why bothering with elliptic curves if RSA works well? A quick answer is given by NIST, which provides with a table that compares RSA and ECC key sizes required to achieve the same level of security. RSA key size (bits) ECC key size (bits) 1024 160 2048 224 3072 256 7680 384 15360 521 Note that there is no linear relationship between the RSA key sizes and the ECC key sizes (in other words: if we double the RSA key size, we don't have to double the ECC key size). This table tells us not only that ECC uses less memory, but also that key generation and signing are considerably faster. But why is it so? The answer is that the faster algorithms for computing discrete logarithms over elliptic curves are Pollard's rho and baby-step giant-step, while in the case of RSA we have faster algorithms. One in particular is the general number field sieve : an algorithm for integer factorization that can be used to compute discrete logarithms. The general number field sieve is the fastest algorithm for integer factorization to date. All of this applies to other cryptosystems based on modular arithmetic as well, including DSA, D-H and ElGamal. Hidden threats of NSA An now the hard part. So far we have discussed algorithms and mathematics. Now it's time to discuss people, and things get more complicated. If you remember, in the last post we said that certain classes of elliptic curves are weak, and to solve the problem of trusting curves from dubious sources we added a random seed to our domain parameters. And if we look at standard curves from NIST we can see that they are all verifiably random. If we read the Wikipedia page for \" nothing up my sleeve \", we can see that: The random numbers for MD5 come from the sine of integers. The random numbers for Blowfish come from the first digits of $\\pi$. The random numbers for RC5 come from both $e$ and the golden ratio. These numbers are random because their digits are uniformly distributed. And the are also unsuspicious, because they have a justification. Now the question is: where do the random seeds for NIST curves come from? The answer is, sadly: we don't know. Those seeds have no justification at all. Is it possible that NIST has discovered a \"sufficiently large\" class of weak elliptic curves and has tried many possible seeds until they found a vulnerable curve? I can't answer this question, but this is a legit and important question. We know that NIST has succeeded in standardizing at least a vulnerable random number generator (a generator which, oddly enough, is based on elliptic curves). Perhaps they also succeeded in standardizing a set of weak elliptic curves. How do we know? We can't. What's important to understand is that \"verifiably random\" and \"secure\" are not synonyms. And it doesn't matter how hard the logarithm problem is, or how long our keys are, if our algorithms are broken, there's nothing we can do. With respect to this, RSA wins, as it does not require special domain parameters that can be tampered. RSA (as well as other modular arithmetic systems) may be a good alternative if we can't trust authorities and if we can't construct our own domain parameters. And in case you are asking: yes, TLS may use NIST curves. If you check https://google.com , you'll see that the connection is using ECDHE and ECDSA, with a certificate based on prime256v1 (aka secp256p1 ). That's all! I hope you have enjoyed this series. My aim was to give you the basic knowledge, terminology and conventions to understand what elliptic curve cryptography today is. If I reached my aim, you should now be able to understand existing ECC-based cryptosystems and to expand your knowledge by reading \"not so gentle\" documentation. When writing this series, I could have skipped over many details and use a simpler terminology, but I felt that by doing so you would have not been able to understand what the web has to offer. I believe I have found a good compromise between simplicity and completeness. Note though that by reading just this series, you are not able to implement secure ECC cryptosystems: security requires us to know many subtle but important details. Remember the requirements for Smart's attack and Sony's mistake — these are just two examples that should teach you how easy is to produce insecure algorithms and how easy it is to exploit them. So, if you are interested in diving deeper into the world of ECC, where to go from here? First off, so far we have seen Weierstrass curves over prime fields, but you must know that there exist other kinds of curve and fields, in particular: Koblitz curves over binary fields. Those are elliptic curves in the form $y&#94;2 + xy = x&#94;3 + ax&#94;2 + 1$ (where $a$ is either 0 or 1) over finite fields containing $2&#94;m$ elements (where $m$ is a prime). They allow particularly efficient point additions and scalar multiplications. Examples of standardized Koblitz curves are nistk163 , nistk283 and nistk571 (three curves defined over a field of 163, 283 and 571 bits). Binary curves. They are very similar to Koblitz curves and are in the form $x&#94;2 + xy = x&#94;3 + x&#94;2 + b$ (where $b$ is an integer often generated from a random seed). As the name suggests, binary curves are restricted to binary fields too. Examples of standardized curves are nistb163 , nistb283 and nistb571 . It must be said that there are growing concerns that both Koblitz and Binary curves may not be as safe as prime curves. Edwards curves , in the form $x&#94;2 + y&#94;2 = 1 + d x&#94;2 y&#94;2$ (where $d$ is either 0 or 1). These are particularly interesting not only because point addition and scalar multiplication are fast, but also because the formula for point addition is always the same, in any case ($P \\ne Q$, $P = Q$, $P = -Q$, ...). This feature leverages the possibility of side-channel attacks, where you measure the time used for scalar multiplication and try to guess the scalar coefficient based on the time it took to compute. Edwards curves are relatively new (they were presented in 2007) and no authority such as Certicom or NIST have yet standardized any of them. Curve25519 and Ed25519 are two particular elliptic curves designed for ECDH and a variant of ECDSA respectively. Like Edwards curves, these two curves are fast and help preventing side-channel attacks. And like Edwards curves, these two curves have not been standardized yet and we can't find them in any popular software (except OpenSSH, that supports Ed25519 key pairs since 2014). If you are interested in the implementation details of ECC, then I suggest you read the sources of OpenSSL and GnuTLS . Finally, if you are interested in the mathematical details, rather than the security and efficiency of the algorithms, you must know that: Elliptic curves are algebraic varieties with genus one . Points at infinity are studied in projective geometry and can be represented using homogeneous coordinates (although most of the features of projective geometry are not needed for elliptic curve cryptography). And don't forget to study finite fields and field theory . These are the keywords that you should look up if you're interested in the topics. Now the series is officially concluded. Thank you for all your friendly comments, tweets and mails. Many have asked me if I'm going to write other series on other closely related topics. The answer is: maybe. I accept suggestions, but I can't promise anything. Thanks for reading and see you next time!","title":"Elliptic Curve Cryptography: breaking security and a comparison with RSA"},{"tags":"cryptography","url":"http://andrea.corbellini.name/2015/05/30/elliptic-curve-cryptography-ecdh-and-ecdsa/","text":"This post is the third in the series ECC: a gentle introduction . In the previous posts, we have seen what an elliptic curve is and we have defined a group law in order to do some math with the points of elliptic curves. Then we have restricted elliptic curves to finite fields of integers modulo a prime . With this restriction, we have seen that the points of elliptic curves generate cyclic subgrups and we have introduced the terms base point , order and cofactor . Finally, we have seen that scalar multiplication in finite fields is an \"easy\" problem, while the discrete logarithm problem seems to be \"hard\". Now we'll see how all of this applies to cryptography. Domain parameters Our elliptic curve algorithms will work in a cyclic subgroup of an elliptic curve over a finite field. Therefore, our algorithms will need the following parameters: The prime $p$ that specifies the size of the finite field. The coefficients $a$ and $b$ of the elliptic curve equation. The base point $G$ that generates our subgroup. The order $n$ of the subgrouop. The cofactor $h$ of the subgroup. In conclusion, the domain parameters for our algorithms are the sextuple $(p, a, b, G, n, h)$ . Random curves When I said that the discrete logarithm problem was \"hard\", I wasn't entirely right. There are some classes of elliptic curves that are particularly weak and allow the use of special purpose algorithms to solve the discrete logarithm problem efficiently. For example, all the curves that have $p = hn$ (that is, the order of the finite field is equal to the order of the elliptic curve) are vulnerable to Smart's attack , which can be used to solve discrete logarithms in polynomial time on a classical computer. Now, suppose that I give you the domain parameters of a curve. There's the possibility that I've discovered a new class of weak curves that nobody knows, and probably I have built a \"fast\" algorithm for computing discrete logarithms on the curve I gave you. How can I convince you of the contrary, i.e. that I'm not aware of any vulnerability? How can I assure you that the curve is \"safe\" (in the sense that it can't be used for special purpose attacks by me)? In an attempt to solve this kind of problem, sometimes we have an additional domain parameter: the seed $S$ . This is a random number used to generate the coefficients $a$ and $b$, or the base point $G$, or both. These parameters are generated by computing the hash of the seed $S$. Hashes, as we know, are \"easy\" to compute, but \"hard\" to reverse. A simple sketch of how a random curve is generated from a seed: the hash of a random number is used to calculate different parameters of the curve. If we wanted to cheat and try to construct a seed from the domain parameters, we would have to solve a \"hard\" problem: hash inversion. A curve generated through a seed is said to be verifiably random . The principle of using hashes to generate parameters is known as \" nothing up my sleeve \", and is commonly used in cryptography. This trick should give some sort of assurance that the curve has not been specially crafted to expose vulnerabilities known to the author . In fact, if I give you a curve together with a seed, it means I was not free to arbitrarily choose the parameters $a$ and $b$, and you should be relatively sure that the curve cannot be used for special purpose attacks by me. The reason why I say \"relatively\" will be explained in the next post. A standardized algorithm for generating and checking random curves is described in ANSI X9.62 and is based on SHA-1 . If you are curious, you can read the algorithms for generating verifiable random curves on a specification by SECG (look for \"Verifiably Random Curves and Base Point Generators\"). I've created a tiny Python script that verifies all the random curves currently shipped with OpenSSL . I strongly recommend you to check it out! Elliptic Curve Cryptography It took us a long time, but finally here we are! Therefore, pure and simple: The private key is a random integer $d$ chosen from $\\{1, \\dots, n - 1\\}$ (where $n$ is the order of the subgroup). The public key is the point $H = dG$ (where $G$ is the base point of the subgroup). You see? If we know $d$ and $G$ (along with the other domain parameters), finding $H$ is \"easy\". But if we know $H$ and $G$, finding the private key $d$ is \"hard\", because it requires us to solve the discrete logarithm problem . Now we are going to describe two public-key algorithms based on that: ECDH (Elliptic curve Diffie-Hellman), which is used for encryption, and ECDSA (Elliptic Curve Digital Signature Algorithm), used for digital signing. Encryption with ECDH ECDH is a variant of the Diffie-Hellman algorithm for elliptic curves. It is actually a key-agreement protocol , more than an encryption algorithm. This basically means that ECDH defines (to some extent) how keys should be generated and exchanged between parties. How to actually encrypt data using such keys is up to us. The problem it solves is the following: two parties (the usual Alice and Bob ) want to exchange information securely, so that a third party (the Man In the Middle ) may intercept them, but may not decode them. This is one of the principles behind TLS, just to give you an example. Here's how it works: First, Alice and Bob generate their own private and public keys . We have the private key $d_A$ and the public key $H_A = d_AG$ for Alice, and the keys $d_B$ and $H_B = d_BG$ for Bob. Note that both Alice and Bob are using the same domain parameters: the same base point $G$ on the same elliptic curve on the same finite field. Alice and Bob exchange their public keys $H_A$ and $H_B$ over an insecure channel . The Man In the Middle would intercept $H_A$ and $H_B$, but won't be able to find out neither $d_A$ nor $d_B$ without solving the discrete logarithm problem. Alice calculates $S = d_A H_B$ (using her own private key and Bob's public key), and Bob calculates $S = d_B H_A$ (using his own private key and Alice's public key). Note that $S$ is the same for both Alice and Bob, in fact: $$S = d_A H_B = d_A (d_B G) = d_B (d_A G) = d_B H_A$$ The Man In the Middle, however, only knows $H_A$ and $H_B$ (together with the other domain parameters) and would not be able to find out the shared secret $S$ . This is known as the Diffie-Hellman problem, which can be stated as follows: Given three points $P$, $aP$ and $bP$, what is the result of $abP$? Or, equivalently: Given three integers $k$, $k&#94;x$ and $k&#94;y$, what is the result of $k&#94;{xy}$? (The latter form is used in the original Diffie-Hellman algorithm, based on modular arithmetic.) The Diffie-Hellman key exchange: Alice and Bob can \"easily\" calculate the shared secret, the Man in the Middle has to solve a \"hard\" problem. The principle behind the Diffie-Hellman problem is also explained in a great YouTube video by Khan Academy , which later explains the Diffie-Hellman algorithm applied to modular arithmetic (not to elliptic curves). The Diffie-Hellman problem for elliptic curves is assumed to be a \"hard\" problem. It is believed to be as \"hard\" as the discrete logarithm problem, although no mathematical proofs are available. What we can tell for sure is that it can't be \"harder\", because solving the logarithm problem is a way of solving the Diffie-Hellman problem. Now that Alice and Bob have obtained the shared secret, they can exchange data with symmetric encryption. For example, they can use the $x$ coordinate of $S$ as the key to encrypt messages using secure ciphers like AES or 3DES . This is more or less what TLS does, the difference is that TLS concatenates the $x$ coordinate with other numbers relative to the connection and then computes a hash of the resulting byte string. Playing with ECDH I've created another Python script for computing public/private keys and shared secrets over an elliptic curve . Unlike all the examples we have seen till now, this script makes use of a standardized curve, rather than a simple curve on a small field. The curve I've chosen is secp256k1 , from SECG (the \"Standards for Efficient Cryptography Group\", founded by Certicom ). This same curve is also used by Bitcoin for digital signatures. Here are the domain parameters: $p$ = 0xffffffff ffffffff ffffffff ffffffff ffffffff ffffffff fffffffe fffffc2f $a$ = 0 $b$ = 7 $x_G$ = 0x79be667e f9dcbbac 55a06295 ce870b07 029bfcdb 2dce28d9 59f2815b 16f81798 $y_G$ = 0x483ada77 26a3c465 5da4fbfc 0e1108a8 fd17b448 a6855419 9c47d08f fb10d4b8 $n$ = 0xffffffff ffffffff ffffffff fffffffe baaedce6 af48a03b bfd25e8c d0364141 $h$ = 1 (These numbers were taken from OpenSSL source code .) Of course, you are free to modify the script to use other curves and domain parameters, just be sure to use prime fields and curves Weierstrass normal form, otherwise the script won't work. The script is really simple and includes some of the algorithms we have described so far: point addition, double and add, ECDH. I recommend you to read and run it. It will produce an output like this: Curve : secp256k1 Alice 's private key: 0xe32868331fa8ef0138de0de85478346aec5e3912b6029ae71691c384237a3eeb Alice' s public key : ( 0x86b1aa5120f079594348c67647679e7ac4c365b2c01330db782b0ba611c1d677 , 0x5f4376a23eed633657a90f385ba21068ed7e29859a7fab09e953cc5b3e89beba ) Bob 's private key: 0xcef147652aa90162e1fff9cf07f2605ea05529ca215a04350a98ecc24aa34342 Bob' s public key : ( 0x4034127647bb7fdab7f1526c7d10be8b28174e2bba35b06ffd8a26fc2c20134a , 0x9e773199edc1ea792b150270ea3317689286c9fe239dd5b9c5cfd9e81b4b632 ) Shared secret : ( 0x3e2ffbc3aa8a2836c1689e55cd169ba638b58a3a18803fcf7de153525b28c3cd , 0x43ca148c92af58ebdb525542488a4fe6397809200fe8c61b41a105449507083 ) Ephemeral ECDH Some of you may have heard of ECDHE instead of ECDH. The \"E\" in ECHDE stands for \"Ephemeral\" and refers to the fact that the keys exchanged are temporary , rather than static. ECDHE is used, for example, in TLS, where both the client and the server generate their public-private key pair on the fly, when the connection is established. The keys are then signed with the TLS certificate (for authentication) and exchanged between the parties. Signing with ECDSA The scenario is the following: Alice wants to sign a message with her private key ($d_A$), and Bob wants to validate the signature using Alice's public key ($H_A$). Nobody but Alice should be able to produce valid signatures. Everyone should be able to check signatures. Again, Alice and Bob are using the same domain parameters. The algorithm we are going to see is ECDSA, a variant of the Digital Signature Algorithm applied to elliptic curves. ECDSA works on the hash of the message, rather than on the message itself. The choice of the hash function is up to us, but it should be obvious that a cryptographically-secure hash function should be chosen. The hash of the message ought to be truncated so that the bit length of the hash is the same as the bit length of $n$ (the order of the subgroup). The truncated hash is an integer and will be denoted as $z$. The algorithm performed by Alice to sign the message works as follows: Take a random integer $k$ chosen from $\\{1, \\dots, n - 1\\}$ (where $n$ is still the subgroup order). Calculate the point $P = kG$ (where $G$ is the base point of the subgroup). Calculate the number $r = x_P \\bmod{n}$ (where $x_P$ is the $x$ coordinate of $P$). If $r = 0$, then choose another $k$ and try again. Calculate $s = k&#94;{-1} (z + rd_A) \\bmod{n}$ (where $d_A$ is Alice's private key and $k&#94;{-1}$ is the multiplicative inverse of $k$ modulo $n$). If $s = 0$, then choose another $k$ and try again. The pair $(r, s)$ is the signature . Alice signs the hash $z$ using her private key $d_A$ and a random $k$. Bob verifies that the message has been correctly signed using Alice's public key $H_A$. In plain words, this algorithm first generates a secret ($k$). This secret is hidden in $r$ thanks to point multiplication (that, as we know, is \"easy\" one way, and \"hard\" the other way round). $r$ is then bound to the message hash by the equation $s = k&#94;{-1} (z + rd_A) \\bmod{n}$. Note that in order to calculate $s$, we have computed the inverse of $k$ modulo $n$. We have already said in the previous post that this is guaranteed to work only if $n$ is a prime number. If a subgroup has a non-prime order, ECDSA can't be used. It's not by chance that almost all standardized curves have a prime order, and those that have a non-prime order are unsuitable for ECDSA. Verifying signatures In order to verify the signature we'll need Alice's public key $H_A$, the (truncated) hash $z$ and, obviously, the signature $(r, s)$. Calculate the integer $u_1 = s&#94;{-1} z \\bmod{n}$. Calculate the integer $u_2 = s&#94;{-1} r \\bmod{n}$. Calculate the point $P = u_1 G + u_2 H_A$. The signature is valid only if $r = x_P \\bmod{n}$. Correctness of the algorithm The logic behind this algorithm may not seem obvious at a first sight, however if we put together all the equations we have written so far, things will be clearer. Let's start from $P = u_1 G + u_2 H_A$. We know, from the definition of public key, that $H_A = d_A G$ (where $d_A$ is the private key). We can write: $$\\begin{array}{rl} P & = u_1 G + u_2 H_A \\\\ & = u_1 G + u_2 d_A G \\\\ & = (u_1 + u_2 d_A) G \\end{array}$$ Using the definitions of $u_1$ and $u_2$, we can write: $$\\begin{array}{rl} P & = (u_1 + u_2 d_A) G \\\\ & = (s&#94;{-1} z + s&#94;{-1} r d_A) G \\\\ & = s&#94;{-1} (z + r d_A) G \\end{array}$$ Here we have omitted \"$\\text{mod}\\ n$\" both for brevity, and because the cyclic subgroup generated by $G$ has order $n$, hence \"$\\text{mod}\\ n$\" is superfluous. Previously, we defined $s = k&#94;{-1} (z + rd_A) \\bmod{n}$. Multiplying each side of the equation by $k$ and dividing by $s$, we get: $k = s&#94;{-1} (z + rd_A) \\bmod{n}$. Substituting this result in our equation for $P$, we get: $$\\begin{array}{rl} P & = s&#94;{-1} (z + r d_A) G \\\\ & = k G \\end{array}$$ This is the same equation for $P$ we had at step 2 of the signature generation algorithm! When generating signatures and when verifying them, we are calculating the same point $P$, just with a different set of equations. This is why the algorithm works. Playing with ECDSA Of course, I've created a Python script for signature generation and verification . The code shares some parts with the ECDH script, in particular the domain parameters and the public/private key pair generation algorithm. Here is the kind of output produced by the script: Curve : secp256k1 Private key : 0x9f4c9eb899bd86e0e83ecca659602a15b2edb648e2ae4ee4a256b17bb29a1a1e Public key : ( 0xabd9791437093d377ca25ea974ddc099eafa3d97c7250d2ea32af6a1556f92a , 0x3fe60f6150b6d87ae8d64b78199b13f26977407c801f233288c97ddc4acca326 ) Message : b 'Hello!' Signature : ( 0xddcb8b5abfe46902f2ac54ab9cd5cf205e359c03fdf66ead1130826f79d45478 , 0x551a5b2cd8465db43254df998ba577cb28e1ee73c5530430395e4fba96610151 ) Verification : signature matches Message : b 'Hi there!' Verification : invalid signature Message : b 'Hello!' Public key : ( 0xc40572bb38dec72b82b3efb1efc8552588b8774149a32e546fb703021cf3b78a , 0x8c6e5c5a9c1ea4cad778072fe955ed1c6a2a92f516f02cab57e0ba7d0765f8bb ) Verification : invalid signature As you can see, the script first signs a message (the byte string \"Hello!\"), then verifies the signature. Afterwards, it tries to verify the same signature against another message (\"Hi there!\") and verification fails. Lastly, it tries to verify the signature against the correct message, but using another random public key and verification fails again. The importance of k When generating ECDSA signatures, it is important to keep the secret $k$ really secret. If we used the same $k$ for all signatures, or if our random number generator were somewhat predictable, an attacker would be able to find out the private key ! This is the kind of mistake made by Sony a few years ago. Basically, the PlayStation 3 game console can run only games signed by Sony with ECDSA. This way, if I wanted to create a new game for PlayStation 3, I couldn't distribute it to the public without a signature from Sony. The problem is: all the signatures made by Sony were generated using a static $k$. (Apparently, Sony's random number generator was inspired by either XKCD or Dilbert .) In this situation, we could easily recover Sony's private key $d_S$ by buying just two signed games, extracting their hashes ($z_1$ and $z_2$) and their signatures ($(r_1, s_1)$ and $(r_2, s_2)$), together with the domain parameters. Here's how: First off, note that $r_1 = r_2$ (because $r = x_P \\bmod{n}$ and $P = kG$ is the same for both signatures). Consider that $(s_1 - s_2) \\bmod{n} = k&#94;{-1} (z_1 - z_2) \\bmod{n}$ (this result comes directly from the equation for $s$). Now multiply each side of the equation by $k$: $k (s_1 - s_2) \\bmod{n} = (z_1 - z_2) \\bmod{n}$. Divide by $(s_1 - s_2)$ to get $k = (z_1 - z_2)(s_1 - s_2)&#94;{-1} \\bmod{n}$. The last equation lets us calculate $k$ using only two hashes and their corresponding signatures. Now we can extract the private key using the equation for $s$: $$s = k&#94;{-1}(z + rd_S) \\bmod{n}\\ \\ \\Rightarrow\\ \\ d_S = r&#94;{-1} (sk - z) \\bmod{n}$$ Similar techniques may be employed if $k$ is not static but predictable in some way. Have a great weekend I really hope you enjoyed what I've written here. As usual, don't hesitate to leave a comment or send me a poke if you need help with something. Next week I'll publish the fourth and last article of this series. It'll be about techniques for solving discrete logarithms, some important problems of Elliptic Curve cryptography, and how ECC compares with RSA. Don't miss it! Read the next post of the series »","title":"Elliptic Curve Cryptography: ECDH and ECDSA"},{"tags":"cryptography","url":"http://andrea.corbellini.name/2015/05/23/elliptic-curve-cryptography-finite-fields-and-discrete-logarithms/","text":"This post is the second in the series ECC: a gentle introduction . In the previous post , we have seen how elliptic curves over the real numbers can be used to define a group. Specifically, we have defined a rule for point addition : given three aligned points, their sum is zero ($P + Q + R = 0$). We have derived a geometric method and an algebraic method for computing point additions. We then introduced scalar multiplication ($nP = P + P + \\cdots + P$) and we found out an \"easy\" algorithm for computing scalar multiplication: double and add . Now we will restrict our elliptic curves to finite fields , rather than the set of real numbers, and see how things change. The field of integers modulo p A finite field is, first of all, a set with a finite number of elements. An example of finite field is the set of integers modulo $p$, where $p$ is a prime number. It is generally denoted as $\\mathbb{Z}/p$, $GF(p)$ or $\\mathbb{F}_p$. We will use the latter notation. In fields we have two binary operations: addition (+) and multiplication (·). Both are closed, associative and commutative. For both operations, there exist a unique identity element, and for every element there's a unique inverse element. Finally, multiplication is distributive over the addition: $x \\cdot (y + z) = x \\cdot y + x \\cdot z$. The set of integers modulo $p$ consists of all the integers from 0 to $p - 1$ . Addition and multiplication work as in modular arithmetic (also known as \"clock arithmetic\"). Here are a few examples of operations in $\\mathbb{F}_{23}$: Addition: $(18 + 9) \\bmod{23} = 4$ Subtraction: $(7 - 14) \\bmod{23} = 16$ Multiplication: $4 \\cdot 7 \\bmod{23} = 5$ Additive inverse: $-5 \\bmod{23} = 18$ Indeed: $(5 + (-5)) \\bmod{23} = (5 + 18) \\bmod{23} = 0$ Multiplicative inverse: $9&#94;{-1} \\bmod{23} = 18$ Indeed: $9 \\cdot 9&#94;{-1} \\bmod{23} = 9 \\cdot 18 \\bmod{23} = 1$ If these equations don't look familiar to you and you need a primer on modular arithmetic, check out Khan Academy . As we already said, the integers modulo $p$ are a field, and therefore all the properties listed above hold. Note that the requirement for $p$ to be prime is important! The set of integers modulo 4 is not a field: 2 has no multiplicative inverse (i.e. the equation $2 \\cdot x \\bmod{4} = 1$ has no solutions). Division modulo p We will soon define elliptic curves over $\\mathbb{F}_p$, but before doing so we need a clear idea of what $x / y$ means in $\\mathbb{F}_p$. Simply put: $x / y = x \\cdot y&#94;{-1}$, or, in plain words, $x$ over $y$ is equal to $x$ times the multiplicative inverse of $y$. This fact is not surprising, but gives us a basic method to perform division: find the multiplicative inverse of a number and then perform a single multiplication . Computing the multiplicative inverse can be \"easily\" done with the extended Euclidean algorithm , which is $O(\\log p)$ (or $O(k)$ if we consider the bit length) in the worst case. We won't enter the details of the extended Euclidean algorithm, as it is off-topic, however here's a working Python implementation: def extended_euclidean_algorithm ( a , b ): \"\"\" Returns a three-tuple (gcd, x, y) such that a * x + b * y == gcd, where gcd is the greatest common divisor of a and b. This function implements the extended Euclidean algorithm and runs in O(log b) in the worst case. \"\"\" s , old_s = 0 , 1 t , old_t = 1 , 0 r , old_r = b , a while r != 0 : quotient = old_r // r old_r , r = r , old_r - quotient * r old_s , s = s , old_s - quotient * s old_t , t = t , old_t - quotient * t return old_r , old_s , old_t def inverse_of ( n , p ): \"\"\" Returns the multiplicative inverse of n modulo p. This function returns an integer m such that (n * m) % p == 1. \"\"\" gcd , x , y = extended_euclidean_algorithm ( n , p ) assert ( n * x + p * y ) % p == gcd if gcd != 1 : # Either n is 0, or p is not a prime number. raise ValueError ( '{} has no multiplicative inverse ' 'modulo {}' . format ( n , p )) else : return x % p Elliptic curves in $\\mathbb{F}_p$ Now we have all the necessary elements to restrict elliptic curves over $\\mathbb{F}_p$. The set of points, that in the previous post was: $$\\begin{array}{rcl} \\left\\{(x, y) \\in \\mathbb{R}&#94;2 \\right. & \\left. | \\right. & \\left. y&#94;2 = x&#94;3 + ax + b, \\right. \\\\ & & \\left. 4a&#94;3 + 27b&#94;2 \\ne 0\\right\\}\\ \\cup\\ \\left\\{0\\right\\} \\end{array}$$ now becomes: $$\\begin{array}{rcl} \\left\\{(x, y) \\in (\\mathbb{F}_p)&#94;2 \\right. & \\left. | \\right. & \\left. y&#94;2 \\equiv x&#94;3 + ax + b \\pmod{p}, \\right. \\\\ & & \\left. 4a&#94;3 + 27b&#94;2 \\not\\equiv 0 \\pmod{p}\\right\\}\\ \\cup\\ \\left\\{0\\right\\} \\end{array}$$ where 0 is still the point at infinity, and $a$ and $b$ are two integers in $\\mathbb{F}_p$. The curve $y&#94;2 \\equiv x&#94;3 - 7x + 10 \\pmod{p}$ with $p = 19, 97, 127, 487$. Note that, for every $x$, there are at most two points. Also note the symmetry about $y = p / 2$. The curve $y&#94;2 \\equiv x&#94;3 \\pmod{29}$ is singular and has a triple point in $(0, 0)$. It is not a valid elliptic curve. What previously was a continuous curve is now a set of disjoint points in the $xy$-plane. But we can prove that, even if we have restricted our domain, elliptic curves in $\\mathbb{F}_p$ still form an abelian group . Point addition Clearly, we need to change a bit our definition of addition in order to make it work in $\\mathbb{F}_p$. With reals, we said that the sum of three aligned points was zero ($P + Q + R = 0$). We can keep this definition, but what does it mean for three points to be aligned in $\\mathbb{F}_p$? We can say that three points are aligned if there's a line that connects all of them . Now, of course, lines in $\\mathbb{F}_p$ are not the same as lines in $\\mathbb{R}$. We can say, informally, that a line in $\\mathbb{F}_p$ is the set of points $(x, y)$ that satisfy the equation $ax + by + c \\equiv 0 \\pmod{p}$ (this is the standard line equation, with the addition of \"$(\\text{mod}\\ p)$\"). Point addition over the curve $y&#94;2 \\equiv x&#94;3 - x + 3 \\pmod{127}$, with $P = (16, 20)$ and $Q = (41, 120)$. Note how the line $y \\equiv 4x + 83 \\pmod{127}$ that connects the points \"repeats\" itself in the plane. Given that we are in a group, point addition retains the properties we already know: $Q + 0 = 0 + Q = Q$ (from the definition of identity element). Given a non-zero point $Q$, the inverse $-Q$ is the point having the same abscissa but opposite ordinate. Or, if you prefer, $-Q = (x_Q, -y_Q \\bmod{p})$. For example, if a curve in $\\mathbb{F}_{29}$ has a point $Q = (2, 5)$, the inverse is $-Q = (2, -5 \\bmod{29}) = (2, 24)$. Also, $P + (-P) = 0$ (from the definition of inverse element). Algebraic sum The equations for calculating point additions are exactly the same as in the previous post , except for the fact that we need to add \"$\\text{mod}\\ p$\" at the end of every expression. Therefore, given $P = (x_P, y_P)$, $Q = (x_Q, y_Q)$ and $R = (x_R, y_R)$, we can calculate $P + Q = -R$ as follows: $$\\begin{array}{rcl} x_R & = & (m&#94;2 - x_P - x_Q) \\bmod{p} \\\\ y_R & = & [y_P + m(x_R - x_P)] \\bmod{p} \\\\ & = & [y_Q + m(x_R - x_Q)] \\bmod{p} \\end{array}$$ If $P \\ne Q$, the the slope $m$ assumes the form: $$m = (y_P - y_Q)(x_P - x_Q)&#94;{-1} \\bmod{p}$$ Else, if $P = Q$, we have: $$m = (3 x_P&#94;2 + a)(2 y_P)&#94;{-1} \\bmod{p}$$ It's not a coincidence that the equations have not changed: in fact, these equations work in every field, finite or infinite (with the exception of $\\mathbb{F}_2$ and $\\mathbb{F}_3$, which are special cased). Now I feel I have to provide a justification for this fact. The problem is: proofs for the group law generally involve complex mathematical concepts. However, I found out a proof from Stefan Friedl that uses only elementary concepts. Read it if you are interested in why these equations work in (almost) every field. Back to us — we won't define a geometric method: in fact, there are a few problems with that. For example, in the previous post, we said that to compute $P + P$ we needed to take the tangent to the curve in $P$. But without continuity, the word \"tangent\" does not make any sense. We can workaround this and other problems, however a pure geometric method would just be too complicated and not practical at all. Instead, you can play with the interactive tool I've written for computing point additions . The order of an elliptic curve group We said that an elliptic curve defined over a finite field has a finite number of points. An important question that we need to answer is: how many points are there exactly? Firstly, let's say that the number of points in a group is called the order of the group . Trying all the possible values for $x$ from 0 to $p - 1$ is not a feasible way to count the points, as it would require $O(p)$ steps, and this is \"hard\" if $p$ is a large prime. Luckily, there's a faster algorithm for computing the order: Schoof's algorithm . I won't enter the details of the algorithm — what matters is that it runs in polynomial time, and this is what we need. Scalar multiplication and cyclic subgroups As with reals, multiplication can be defined as: $$n P = \\underbrace{P + P + \\cdots + P}_{n\\ \\text{times}}$$ And, again, we can use the double and add algorithm to perform multiplication in $O(\\log n)$ steps (or $O(k)$, where $k$ is the number of bits of $n$). I've written an interactive tool for scalar multiplication too. Multiplication over points for elliptic curves in $\\mathbb{F}_p$ has an interesting property. Take the curve $y&#94;2 \\equiv x&#94;3 + 2x + 3 \\pmod{97}$ and the point $P = (3, 6)$. Now calculate all the multiples of $P$: The multiples of $P = (3, 6)$ are just five distinct points ($0$, $P$, $2P$, $3P$, $4P$) and they are repeating cyclically. It's easy to spot the similarity between scalar multiplication on elliptic curves and addition in modular arithmetic. $0P = 0$ $1P = (3, 6)$ $2P = (80, 10)$ $3P = (80, 87)$ $4P = (3, 91)$ $5P = 0$ $6P = (3, 6)$ $7P = (80, 10)$ $8P = (80, 87)$ $9P = (3, 91)$ ... Here we can immediately spot two things: firstly, the multiples of $P$ are just five: the other points of the elliptic curve never appear. Secondly, they are repeating cyclically . We can write: $5kP = 0$ $(5k + 1)P = P$ $(5k + 2)P = 2P$ $(5k + 3)P = 3P$ $(5k + 4)P = 4P$ for every integer $k$. Note that these five equations can be \"compressed\" into a single one, thanks to the modulo operator: $kP = (k \\bmod{5})P$. Not only that, but we can immediately verify that these five points are closed under addition . Which means: however I add $0$, $P$, $2P$, $3P$ or $4P$, the result is always one of these five points. Again, the other points of the elliptic curve never appear in the results. The same holds for every point, not just for $P = (3, 6)$. In fact, if we take a generic $P$: $$nP + mP = \\underbrace{P + \\cdots + P}_{n\\ \\text{times}} + \\underbrace{P + \\cdots + P}_{m\\ \\text{times}} = (n + m)P$$ Which means: if we add two multiples of $P$, we obtain a multiple of $P$ (i.e. multiples of $P$ are closed under addition). This is enough to prove that the set of the multiples of $P$ is a cyclic subgroup of the group formed by the elliptic curve. A \"subgroup\" is a group which is a subset of another group. A \"cyclic subgroup\" is a subgroup which elements are repeating cyclically, like we have shown in the previous example. The point $P$ is called generator or base point of the cyclic subgroup . Cyclic subgroups are the foundations of ECC and other cryptosystems. We will see why in the next post. Subgroup order We can ask ourselves what the order of a subgroup generated by a point $P$ is (or, equivalently, what the order of $P$ is). To answer this question we can't use Schoof's algorithm, because that algorithm only works on whole elliptic curves, not on subgroups. Before approaching the problem, we need a few more bits: So far, we have the defined the order as the number of points of a group. This definition is still valid, but within a cyclic subgroup we can give a new, equivalent definition: the order of $P$ is the smallest positive integer $n$ such that $nP = 0$ . In fact, if you look at the previous example, our subgroup contained five points, and we had $5P = 0$. The order of $P$ is linked to the order of the elliptic curve by Lagrange's theorem , which states that the order of a subgroup is a divisor of the order of the parent group . In other words, if an elliptic curve contains $N$ points and one of its subgroups contains $n$ points, then $n$ is a divisor of $N$. These two information together give us a way to find out the order of a subgroup with base point $P$: Calculate the elliptic curve's order $N$ using Schoof's algorithm. Find out all the divisors of $N$. For every divisor $n$ of $N$, compute $nP$. The smallest $n$ such that $nP = 0$ is the order of the subgroup. For example, the curve $y&#94;2 = x&#94;3 - x + 3$ over the field $\\mathbb{F}_{37}$ has order $N = 42$. Its subgroups may have order $n = 1$, $2$, $3$, $6$, $7$, $14$, $21$ or $42$. If we try $P = (2, 3)$ we can see that $P \\ne 0$, $2P \\ne 0$, ..., $7P = 0$, hence the order of $P$ is $n = 7$. Note that it's important to take the smallest divisor, not a random one . If we proceeded randomly, we could have taken $n = 14$, which is not the order of the subgroup, but one of its multiples. Another example: the elliptic curve defined by the equation $y&#94;2 = x&#94;3 - x + 1$ over the field $\\mathbb{F}_{29}$ has order $N = 37$, which is a prime. Its subgroups may only have order $n = 1$ or $37$. As you can easily guess, when $n = 1$, the subgroup contains only the point at infinity; when $n = N$, the subgroup contains all the points of the elliptic curve. Finding a base point For our ECC algorithms, we want subgroups with a high order. So in general we will choose an elliptic curve, calculate its order ($N$), choose a high divisor as the subgroup order ($n$) and eventually find a suitable base point. That is: we won't choose a base point and then calculate its order, but we'll do the opposite: we will first choose an order that looks good enough and then we will hunt for a suitable base point. How do we do that? Firstly, we need to introduce one more term. Lagrange's theorem implies that the number $h = N / n$ is always an integer (because $n$ is a divisor of $N$). The number $h$ has a name: it's the cofactor of the subgroup . Now consider that for every point of an elliptic curve we have $NP = 0$. This happens because $N$ is a multiple of any candidate $n$. Using the definition of cofator, we can write: $$n(hP) = 0$$ Now suppose that $n$ is a prime number (for reason that will be explained in the next post, we prefer prime orders). This equation, written in this form, is telling us that the point $G = hP$ generates a subgroup of order $n$ (except when $G = hP = 0$, in which case the subgroup has order 1). In the light of this, we can outline the following algorithm: Calculate the order $N$ of the elliptic curve. Choose the order $n$ of the subgroup. For the algorithm to work, this number must be prime and must be a divisor of $N$. Compute the cofactor $h = N / n$. Choose a random point $P$ on the curve. Compute $G = hP$. If $G$ is 0, then go back to step 4. Otherwise we have found a generator of a subgroup with order $n$ and cofactor $h$. Note that this algorithm only works if $n$ is a prime. If $n$ wasn't a prime, then the order of $G$ could be one of the divisors of $n$. Discrete logarithm As we did when working with continuous elliptic curves, we are now going to discuss the question: if we know $P$ and $Q$, what is $k$ such that $Q = kP$? This problem, which is known as the discrete logarithm problem for elliptic curves, is believed to be a \"hard\" problem, in that there is no known polynomial time algorithm that can run on a classical computer. There are, however, no mathematical proofs for this belief. This problem is also analogous to the one used with other cryptosystems such as the Digital Signature Algorithm (DSA), the Diffie-Hellman key exchange (D-H) and the ElGamal algorithm — it's not a coincidence that they have the same name. The difference is that, with those algorithms, we use modulo exponentiation instead of scalar multiplication. Their discrete logarithm problem can be stated as follows: if we know $a$ and $b$, what's $k$ such that $b = a&#94;k \\bmod{p}$? Both these problems are \"discrete\" because they involve finite sets (more precisely, cyclic subgroups). And they are \"logarithms\" because they are analogous to ordinary logarithms. What makes ECC interesting is that, as of today, the discrete logarithm problem for elliptic curves seems to be \"harder\" if compared to other similar problems used in cryptography. This implies that we need fewer bits for the integer $k$ in order to achieve the same level of security as with other cryptosystems, as we will see in details in the fourth and last post of this series. More next week! Enough for today! I really hope you enjoyed this post. Leave a comment if you didn't. Next week's post will be the third in this series and will be about ECC algorithms: key pair generation, ECDH and ECDSA. That will be one of the most interesting parts of this series. Don't miss it! Read the next post of the series »","title":"Elliptic Curve Cryptography: finite fields and discrete logarithms"},{"tags":"cryptography","url":"http://andrea.corbellini.name/2015/05/17/elliptic-curve-cryptography-a-gentle-introduction/","text":"Those of you who know what public-key cryptography is may have already heard of ECC , ECDH or ECDSA . The first is an acronym for Elliptic Curve Cryptography, the others are names for algorithms based on it. Today, we can find elliptic curves cryptosystems in TLS , PGP and SSH , which are just three of the main technologies on which the modern web and IT world are based. Not to mention Bitcoin and other cryptocurrencies. Before ECC become popular, almost all public-key algorithms were based on RSA, DSA, and DH, alternative cryptosystems based on modular arithmetic. RSA and friends are still very important today, and often are used alongside ECC. However, while the magic behind RSA and friends can be easily explained, is widely understood, and rough implementations can be written quite easily , the foundations of ECC are still a mystery to most. With a series of blog posts I'm going to give you a gentle introduction to the world of elliptic curve cryptography. My aim is not to provide a complete and detailed guide to ECC (the web is full of information on the subject), but to provide a simple overview of what ECC is and why it is considered secure , without losing time on long mathematical proofs or boring implementation details. I will also give helpful examples together with visual interactive tools and scripts to play with . Specifically, here are the topics I'll touch: Elliptic curves over real numbers and the group law (covered in this blog post) Elliptic curves over finite fields and the discrete logarithm problem Key pair generation and two ECC algorithms: ECDH and ECDSA Algorithms for breaking ECC security, and a comparison with RSA In order to understand what's written here, you'll need to know some basic stuff of set theory, geometry and modular arithmetic, and have familiarity with symmetric and asymmetric cryptography. Lastly, you need to have a clear idea of what an \"easy\" problem is, what a \"hard\" problem is, and their roles in cryptography. Ready? Let's start! Elliptic Curves First of all: what is an elliptic curve? Wolfram MathWorld gives an excellent and complete definition . But for our aims, an elliptic curve will simply be the set of points described by the equation : $$y&#94;2 = x&#94;3 + ax + b$$ where $4a&#94;3 + 27b&#94;2 \\ne 0$ (this is required to exclude singular curves ). The equation above is what is called Weierstrass normal form for elliptic curves. Different shapes for different elliptic curves ($b = 1$, $a$ varying from 2 to -3). Types of singularities: on the left, a curve with a cusp ($y&#94;2 = x&#94;3$). On the right, a curve with a self-intersection ($y&#94;2 = x&#94;3 - 3x + 2$). None of them is a valid elliptic curve. Depending on the value of $a$ and $b$, elliptic curves may assume different shapes on the plane. As it can be easily seen and verified, elliptic curves are symmetric about the $x$-axis. For our aims, we will also need a point at infinity (also known as ideal point) to be part of our curve. From now on, we will denote our point at infinity with the symbol 0 (zero). If we want to explicitly take into account the point at infinity, we can refine our definition of elliptic curve as follows: $$\\left\\{ (x, y) \\in \\mathbb{R}&#94;2\\ |\\ y&#94;2 = x&#94;3 + ax + b,\\ 4 a&#94;3 + 27 b&#94;2 \\ne 0 \\right\\}\\ \\cup\\ \\left\\{ 0 \\right\\}$$ Groups A group in mathematics is a set for which we have defined a binary operation that we call \"addition\" and indicate with the symbol +. In order for the set $\\mathbb{G}$ to be a group, addition must defined so that it respects the following four properties: closure: if $a$ and $b$ are members of $\\mathbb{G}$, then $a + b$ is a member of $\\mathbb{G}$; associativity: $(a + b) + c = a + (b + c)$; there exists an identity element 0 such that $a + 0 = 0 + a = a$; every element has an inverse , that is: for every $a$ there exists $b$ such that $a + b = 0$. If we add a fifth requirement: commutativity: $a + b = b + a$, then the group is called abelian group . With the usual notion of addition, the set of integer numbers $\\mathbb{Z}$ is a group (moreover, it's an abelian group). The set of natural numbers $\\mathbb{N}$ however is not a group, as the fourth property can't be satisfied. Groups are nice because, if we can demonstrate that those four properties hold, we get some other properties for free. For example: the identity element is unique ; also the inverses are unique , that is: for every $a$ there exists only one $b$ such that $a + b = 0$ (and we can write $b$ as $-a$). Either directly or indirectly, these and other facts about groups will be very important for us later. The group law for elliptic curves We can define a group over elliptic curves. Specifically: the elements of the group are the points of an elliptic curve; the identity element is the point at infinity 0; the inverse of a point $P$ is the one symmetric about the $x$-axis; addition is given by the following rule: given three aligned, non-zero points $P$, $Q$ and $R$, their sum is $P + Q + R = 0$ . The sum of three aligned point is 0. Note that with the last rule, we only require three aligned points, and three points are aligned without respect to order. This means that, if $P$, $Q$ and $R$ are aligned, then $P + (Q + R) = Q + (P + R) = R + (P + Q) = \\cdots = 0$. This way, we have intuitively proved that our + operator is both associative and commutative: we are in an abelian group . So far, so great. But how do we actually compute the sum of two arbitrary points? Geometric addition Thanks to the fact that we are in an abelian group, we can write $P + Q + R = 0$ as $P + Q = -R$. This equation, in this form, lets us derive a geometric method to compute the sum between two points $P$ and $Q$: if we draw a line passing through $P$ and $Q$, this line will intersect a third point on the curve, $R$ (this is implied by the fact that $P$, $Q$ and $R$ are aligned). If we take the inverse of this point, $-R$, we have found the result of $P + Q$ . Draw the line through $P$ and $Q$. The line intersects a third point $R$. The point symmetric to it, $-R$, is the result of $P + Q$. This geometric method works but needs some refinement. Particularly, we need to answer a few questions: What if $P = 0$ or $Q = 0$? Certainly, we can't draw any line (0 is not on the $xy$-plane). But given that we have defined 0 as the identity element, $P + 0 = P$ and $0 + Q = Q$, for any $P$ and for any $Q$. What if $P = -Q$? In this case, the line going through the two points is vertical, and does not intersect any third point. But if $P$ is the inverse of $Q$, then we have $P + Q = P + (-P) = 0$ from the definition of inverse. What if $P = Q$? In this case, there are infinitely many lines passing through the point. Here things start getting a bit more complicated. But consider a point $Q' \\ne P$. What happens if we make $Q'$ approach $P$, getting closer and closer to it? As the two points become closer together, the line passing through them becomes tangent to the curve. As $Q'$ tends towards $P$, the line passing through $P$ and $Q'$ becomes tangent to the curve. In the light of this we can say that $P + P = -R$, where $R$ is the point of intersection between the curve and the line tangent to the curve in $P$. What if $P \\ne Q$, but there is no third point $R$? We are in a case very similar to the previous one. In fact, we are in the case where the line passing through $P$ and $Q$ is tangent to the curve. If our line intersects just two points, then it means that it's tangent to the curve. It's easy to see how the result of the sum becomes symmetric to one of the two points. Let's assume that $P$ is the tangency point. In the previous case, we would have written $P + P = -Q$. That equation now becomes $P + Q = -P$. If, on the other hand, $Q$ were the tangency point, the correct equation would have been $P + Q = -Q$. The geometric method is now complete and covers all cases. With a pencil and a ruler we are able to perform addition involving every point of any elliptic curve. If you want to try, take a look at the HTML5/JavaScript visual tool I've built for computing sums on elliptic curves! Algebraic addition If we want a computer to perform point addition, we need to turn the geometric method into an algebraic method. Transforming the rules described above into a set of equations may seem straightforward, but actually it can be really tedious because it requires solving cubic equations. For this reason, here I will report only the results. First, let's get get rid of the most annoying corner cases. We already know that $P + (-P) = 0$, and we also know that $P + 0 = 0 + P = P$. So, in our equations, we will avoid these two cases and we will only consider two non-zero, non-symmetric points $P = (x_P, y_P)$ and $Q = (x_Q, y_Q)$ . If $P$ and $Q$ are distinct ($x_P \\ne x_Q$), the line through them has slope : $$m = \\frac{y_P - y_Q}{x_P - x_Q}$$ The intersection of this line with the elliptic curve is a third point $R = (x_R, y_R)$: $$\\begin{array}{rcl} x_R & = & m&#94;2 - x_P - x_Q \\\\ y_R & = & y_P + m(x_R - x_P) \\end{array}$$ or, equivalently: $$y_R = y_Q + m(x_R - x_Q)$$ Hence $(x_P, y_P) + (x_Q, y_Q) = (x_R, -y_R)$ (pay attention at the signs and remember that $P + Q = -R$). If we wanted to check whether this result is right, we would have had to check whether $R$ belongs to the curve and whether $P$, $Q$ and $R$ are aligned. Checking whether the points are aligned is trivial, checking that $R$ belongs to the curve is not, as we would need to solve a cubic equation, which is not fun at all. Instead, let's play with an example: according to our visual tool , given $P = (1, 2)$ and $Q = (3, 4)$ over the curve $y&#94;2 = x&#94;3 - 7x + 10$, their sum is $P + Q = -R = (-3, 2)$. Let's see if our equations agree: $$\\begin{array}{rcl} m & = & \\frac{y_P - y_Q}{x_P - x_Q} = \\frac{2 - 4}{1 - 3} = 1 \\\\ x_R & = & m&#94;2 - x_P - x_Q = 1&#94;2 - 1 - 3 = -3 \\\\ y_R & = & y_P + m(x_R - x_P) = 2 + 1 \\cdot (-3 - 1) = -2 \\\\ & = & y_Q + m(x_R - x_Q) = 4 + 1 \\cdot (-3 - 3) = -2 \\end{array}$$ Yes, this is correct! Note that these equations work even if one of $P$ or $Q$ is a tangency point . Let's try with $P = (-1, 4)$ and $Q = (1, 2)$. $$\\begin{array}{rcl} m & = & \\frac{y_P - y_Q}{x_P - x_Q} = \\frac{4 - 2}{-1 - 1} = -1 \\\\ x_R & = & m&#94;2 - x_P - x_Q = (-1)&#94;2 - (-1) - 1 = 1 \\\\ y_R & = & y_P + m(x_R - x_P) = 4 + -1 \\cdot (1 - (-1)) = 2 \\end{array}$$ We get the result $P + Q = (1, -2)$, which is the same result given by the visual tool . The case $P = Q$ needs to be treated a bit differently : the equations for $x_R$ and $y_R$ are the same, but given that $x_P = x_Q$, we must use a different equation for the slope : $$m = \\frac{3 x_P&#94;2 + a}{2 y_P}$$ Note that, as we would expect, this expression for $m$ is the first derivative of: $$y_P = \\pm \\sqrt{x_P&#94;3 + ax_P + b}$$ To prove the validity of this result it is enough to check that $R$ belongs to the curve and that the line passing through $P$ and $R$ has only two intersections with the curve. But again, we don't prove this fact, and instead try with an example: $P = Q = (1, 2)$. $$\\begin{array}{rcl} m & = & \\frac{3x_P&#94;2 + a}{2 y_P} = \\frac{3 \\cdot 1&#94;2 - 7}{2 \\cdot 2} = -1 \\\\ x_R & = & m&#94;2 - x_P - x_Q = (-1)&#94;2 - 1 - 1 = -1 \\\\ y_R & = & y_P + m(x_R - x_P) = 2 + (-1) \\cdot (-1 - 1) = 4 \\end{array}$$ Which gives us $P + P = -R = (-1, -4)$. Correct ! Although the procedure to derive them can be really tedious, our equations are pretty compact. This is thanks to Weierstrass normal form: without it, these equations could have been really long and complicated! Scalar multiplication Other than addition, we can define another operation: scalar multiplication , that is: $$nP = \\underbrace{P + P + \\cdots + P}_{n\\ \\text{times}}$$ where $n$ is a natural number. I've written a visual tool for scalar multiplication too, if you want to play with that. Written in that form, it may seem that computing $nP$ requires $n$ additions. If $n$ has $k$ binary digits, then our algorithm would be $O(2&#94;k)$, which is not really good. But there exist faster algorithms. One of them is the double and add algorithm. Its principle of operation can be better explained with an example. Take $n = 151$. Its binary representation is $10010111_2$. This binary representation can be turned into a sum of powers of two: $$\\begin{array}{rcl} 151 & = & 1 \\cdot 2&#94;7 + 0 \\cdot 2&#94;6 + 0 \\cdot 2&#94;5 + 1 \\cdot 2&#94;4 + 0 \\cdot 2&#94;3 + 1 \\cdot 2&#94;2 + 1 \\cdot 2&#94;1 + 1 \\cdot 2&#94;0 \\\\ & = & 2&#94;7 + 2&#94;4 + 2&#94;2 + 2&#94;1 + 2&#94;0 \\end{array}$$ (We have taken each binary digit of $n$ and multiplied it by a power of two.) In view of this, we can write: $$151 \\cdot P = 2&#94;7 P + 2&#94;4 P + 2&#94;2 P + 2&#94;1 P + 2&#94;0 P$$ What the double and add algorithm tells us to do is: Take $P$. Double it, so that we get $2P$. Add $2P$ to $P$ (in order to get the result of $2&#94;1P + 2&#94;0P$). Double $2P$, so that we get $2&#94;2P$. Add it to our result (so that we get $2&#94;2P + 2&#94;1P + 2&#94;0P$). Double $2&#94;2P$ to get $2&#94;3P$. Don't perform any addition involving $2&#94;3P$. Double $2&#94;3P$ to get $2&#94;4P$. Add it to our result (so that we get $2&#94;4P + 2&#94;2P + 2&#94;1P + 2&#94;0P$). ... In the end, we can compute $151 \\cdot P$ performing just seven doublings and four additions. If this is not clear enough, here's a Python script that implements the algorithm: def bits ( n ): \"\"\" Generates the binary digits of n, starting from the least significant bit. bits(151) -> 1, 1, 1, 0, 1, 0, 0, 1 \"\"\" while n : yield n & 1 n >>= 1 def double_and_add ( n , x ): \"\"\" Returns the result of n * x, computed using the double and add algorithm. \"\"\" result = 0 addend = x for bit in bits ( n ): if bit == 1 : result += addend addend *= 2 return result If doubling and adding are both $O(1)$ operations, then this algorithm is $O(\\log n)$ (or $O(k)$ if we consider the bit length), which is pretty good. Surely much better than the initial $O(n)$ algorithm! Logarithm Given $n$ and $P$, we now have at least one polynomial time algorithm for computing $Q = nP$. But what about the other way round? What if we know $Q$ and $P$ and need to find out $n$ ? This problem is known as the logarithm problem . We call it \"logarithm\" instead of \"division\" for conformity with other cryptosystems (where instead of multiplication we have exponentiation). I don't know of any \"easy\" algorithm for the logarithm problem, however playing with multiplication it's easy to see some patterns. For example, take the curve $y&#94;2 = x&#94;3 - 3x + 1$ and the point $P = (0, 1)$. We can immediately verify that, if $n$ is odd, $nP$ is on the curve on the left semiplane; if $n$ is even, $nP$ is on the curve on the right semiplane. If we experimented more, we could probably find more patterns that eventually could lead us to write an algorithm for computing the logarithm on that curve efficiently. But there's a variant of the logarithm problem: the discrete logarithm problem. As we will see in the next post, if we reduce the domain of our elliptic curves, scalar multiplication remains \"easy\", while the discrete logarithm becomes a \"hard\" problem . This duality is the key brick of elliptic curve cryptography. See you next week That's all for today, I hope you enjoyed this post! Next week we will discover finite fields and the discrete logarithm problem , along with examples and tools to play with. If this stuff sounds interesting to you, then stay tuned! Read the next post of the series »","title":"Elliptic Curve Cryptography: a gentle introduction"},{"tags":"information-technology","url":"http://andrea.corbellini.name/2015/04/12/lets-encrypt-the-road-towards-a-better-web/","text":"I've always dreamed of a encrypted web, where HTTPS is the standard and plain HTTP is no more. A web where eavesdropping or manipulating information is not possible, or at least much harder than today. I remember that I got excited when I first heard of CAcert : \"a community-driven Certificate Authority that issues certificates to the public at large for free\" . Unfortunately, CAcert's root certificate never made it into the major web browsers and operating systems. Whatever the reasons, the result is that visiting a HTTPS website with a certificate released by CAcert produces nothing but a scary warning with a call to leave the site , making CAcert unsuitable for most. StarCom , on the other hand, has made it into the major browsers. But despite its certificates are released for free, it has never become much widespread. Also, StarCom has been heavily criticized for how the Hearbleed vulnerability was handled, and AFAIK this has led many customers away. Let's Encrypt Recently, I learned about Let's Encrypt : a \"free, automated, and open\" Certificate Authority arriving in mid-2015. There are many important facts that make Let's Encrypt different and better from all the other Certificate Authorities out there. I'll let you discover all of them. Probably, the most important fact is that Let's Encrypt has important sponsors , including Mozilla . And this is what matters today, because it gives Let's Encrypt a chance to be included in at least one major browser. Let's Encrypt logo. Another interesting fact about Let's Encrypt is that its certificates are released in a way that is both secure and automated at the same time . This gives the opportunity for other (potential) Certificate Authorities to adopt the same automated system. If Let's Encrypt wins, then everyone will have an easy way to obtain a free HTTPS certificate for their website. The next big step would be making Let's Encrypt increase in adoption and the final step would be deprecating plain HTTP. There are however a few open questions: What will be the answer from Google, Apple, Microsoft and other major browser/operating systems makers? What will be the reaction of VeriSign and Comodo? (That together hold more than 50% of all the certificates currently used on the web.) Will they declare war to Let's Encrypt or will they consolidate their efforts on customer services and Extended Validation? Will the technology behind Let's Encrypt allow the creation of a new model for certificate management? Will we see web servers and providers with built-in support for it? I do not have an answer to these questions, time will tell. However I really hope my dream to become a reality soon. If you, like me, want Let's Encrypt to be a success, then please share and discuss about it. Perhaps, one day, we will find ourselves teaching juniors that HTTPS has not always been the standard... :)","title":"Let's Encrypt: the road towards a better web?"},{"tags":"cloud","url":"http://andrea.corbellini.name/2015/03/25/running-ubuntu-snappy-inside-docker/","text":"Many of you may have already heard of Ubuntu Core . For those who haven't, it's a minimal Ubuntu version, running only a few essential services and ships with a new package manager (snappy) that provides transactional updates. Ubuntu Core provides a lightweight base operating system which is fast to deploy and easy to maintain up to date. It also uses a nice security model . All these characteristics make it particularly appealing for the cloud. And, in fact, people are starting considering it for building their (micro)services architectures. Some weeks ago, a user on Ask Ubuntu asked: Can I run Snappy Ubuntu Core as a guest inside Docker? The problem is that Ubuntu Core does not ship with an official Docker image that we can pull, so we are forced to set it up manually. Here's how. Creating the Docker image Step 1: get the latest Ubuntu Core As of writing, the latest Ubuntu Core image is alpha 3 and can be downloaded with: $ wget http://cdimage.ubuntu.com/ubuntu-core/releases/alpha-3/ubuntu-core-WEBDM-alpha-03_amd64-generic.img.xz (If you browse to cdimage.ubuntu.com , you can also find the signed hashsums.) The downloaded image is XZ-compressed and we need to extract it: $ unxz ubuntu-core-WEBDM-alpha-03_amd64-generic.img.xz Step 2: connect the image using qemu-nbd The file we have just downloaded and extracted is a filesystem dump. The previous version of the image (Alpha 2) was a QCOW2 image (the format used by QEMU). In order to access its contents, we have a few options. Here I'll show one that works with both filesystem dumps and QCOW2 images. The trick consists in using qemu-nbd (a tool from the qemu-utils package): # qemu-nbd -rc /dev/nbd0 ubuntu-core-WEBDM-alpha-03_amd64-generic.img This command will create a virtual device named /dev/nbd0 , with virtual partitions named /dev/nbd0p1 , /dev/nbd0p2 , ... Use fdisk -l /dev/nbd0 to get an idea of what partitions are inside the QCOW2 image. Step 3: mount the filesystem The partition we are interested in is /dev/nbd0p3 , so we need to mount it: # mkdir nbd0p3 # mount -r /dev/nbd0p3 nbd0p3 Step 4: create a base Docker image As suggested on the Docker documentation , creating a base Docker image from a directory is pretty straightforward: tar - C nbd0p3 - c . | docker import - ubuntu - core alpha - 3 Our newly created image will now appear when running docker images : # docker images REPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZE ubuntu-core alpha-3 f6df3c0e2d74 5 seconds ago 543.5 MB Let's verify if we did a good job: # docker run ubuntu-core:alpha-3 snappy Usage:snappy [-h] [-v] {info,versions,search,update-versions,update,rollback,install,uninstall,tags,config,build,booted,chroot,framework,fake-version,nap} ... Yes! We have successfully added Ubuntu Core to the available Docker images and we have run our first snappy container! Installing and running software Without wasting too many words, here's how to install and run the xkcd-webserver snappy package inside docker: # docker run -p 8000:80 ubuntu-core:alpha-3 /bin/sh -c 'snappy install xkcd-webserver && cd /apps/xkcd-webserver/0.3.1 && ./bin/xkcd-webserver' WARN: AppArmor not available when processing AppArmor hook Failed to get D-Bus connection: Operation not permitted Failed to get D-Bus connection: Operation not permitted ** (process:13): WARNING **: user.vala:637: Can not connect to logind xkcd-webserver 21 kB [======================================] OK WARNING: failed to connect to dbus: org.freedesktop.DBus.Error.FileNotFound: Failed to connect to socket /var/run/dbus/system_bus_socket: No such file or directory Part Tag Installed Available Fingerprint Active xkcd-webserver edge 0.3.1 - 3a9152b8bff494 * Now, if you visit http://localhost:8000/ you should see a random XKCD comic. If you have payed attention, you may have noticed a few warnings about AppArmor, DBus and logind. The reason why you are seeing these warnings is pretty simple: we did not start neither AppArmor nor DBus nor logind. Now, generally speaking, we could run init inside Docker and fix these and other warnings. However that's not what Docker is meant for. So if you want to run AppArmor or similar stuff from inside Docker or LXC, then probably you should consider virtualization. Dockerfile Once you have created the base Docker image, you can start creating some Dockerfile s, if you need to. Here's an example: FROM ubuntu-core:alpha-3 RUN snappy install xkcd-webserver EXPOSE 8000:80 CMD cd /apps/xkcd-webserver/0.3.1 && ./bin/xkcd-webserver This Dockerfile does the same job as the previous command: it installs and runs xkcd-webserver on port 8000. In order to use it, first build it: # docker build -t xkcd-webserver . Check that it has been correctly installed: # docker images REPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZE xkcd-webserver latest 260e0116e9e3 3 minutes ago 543.5 MB ubuntu-core alpha-3 f6df3c0e2d74 About an hour ago 543.5 MB Then run it: # docker run xkcd-webserver Again, you should see a random XKCD comic on http://localhost:8000/ . Conclusion That's all folks! I hope you enjoyed this tiny guide, and if you need help, please ask a question on Ask Ubuntu with the ubuntu-core tag , which I'm subscribed to.","title":"Running Ubuntu Snappy inside Docker"},{"tags":"cloud","url":"http://andrea.corbellini.name/2015/02/20/are-lxc-and-docker-secure/","text":"Since its initial release in 2008, LXC has become widespread among servers. Today, it is becoming the preferred deployment strategy in many contexts, also thanks to Docker and, more recently, LXD. LXC and Docker are used not only to achieve modular architecture design, but also as a way to run untrusted code in an isolated environment. We can agree that the LXC and Docker ecosystems are great and work well, but there's an important question that I believe everyone should ask, but too few people are asking: are LXC and Docker secure? A system is as safe as its weakest component. In order to answer this question, I won't go deep into the details of what LXC and Docker are. The web is full of information on namespaces and cgroups . Rather, I'd like to show what LXC and Docker can do, what they cannot do, and what their default configuration allows them to do. My hope is to provide a quick checklist for those who want to go with LXC/Docker, but are unsure on what they need to pay attention to. What LXC and Docker can do As we all know, LXC confines processes mainly thanks to two Linux kernel features: namespaces and cgroups. These provide ways to control and limit access to resource such as memory or filesystem. So, for example, you can limit the bandwidth used by processes inside a container, you can limit the priority of the CPU scheduler, and so on. As it is well known, processes inside a LXC guest cannot: directly interact with the host processes, or with other LXC containers; access the root filesystem, unless configured otherwise; access special devices (block devices, network interfaces, ...), unless configured otherwise; mount arbitrary filesystems; execute special ioctl s, special syscalls or special interrupts, that would affect the behavior host. And at the same time, processes inside an LXC guest can find an environment that is perfectly suitable to run a working operating system: I can run init, I can read from /proc , I can access the internet. This is most of what LXC can do, and it's also what you get by default. Docker (when used with the LXC backend) is a wrapper around LXC that provides utilities for easy deployment and management of the containers, so everything that applies to LXC, applies to Docker too . If this sounds great, then beware that there are the things you should know... You need a security context LXC is somewhat incomplete. What I mean is that some parts of special filesystems like procfs or sysfs are not faked. For example, as of now, I can successfully change the value of host's /proc/sys/kernel/panic or /sys/class/thermal/cooling_device0/cur_state . The reason why LXC is \"incomplete\" doesn't really matter (it's actually the kernel to be incomplete, but anyhow...). What matters is that certain nasty actions can be forbade, not by LXC itself, but by an AppArmor/SELinux profile that blocks read and write access certain /proc and /sys components. The AppArmor rules were shipped in Ubuntu since 12.10 (Quantal), and have been included upstream since early 2014, together with the SELinux rules. Therefore, a security context like AppArmor or SELinux is required to run LXC safely . Without it, the root user inside a guest can take control of the host. Check that AppArmor or SELinux are running and are configured properly. If you want to go with Grsecurity, then remember to configure it manually. Limit resource consumption LXC offers ways to limit resource usage, but no special restrictions are put in place by default. You have to configure them by yourself. With the default configuration, I can run fork-bombs, request huge memory maps, keep all CPUs busy, doing high loads of I/O. All of this without special privileges. Remember this when running untrusted code. To limit resource consumption in LXC, open the configuration file for your container and set the lxc.cgroup.&lt;system&gt; values you need. For example, if you want to limit the container memory usage to 512 MiB, set lxc.cgroup.memory.limit_in_bytes = 512M . Note that the container with that option, once it exceeds the 512 MiB cap, will start using the swap without limits. If this is not what you want, then set lxc.cgroup.memory.memsw.max_usage_in_bytes = 512M . Note that to use both options you may need to add cgroup_enable=memory and swapaccount=1 to the kernel command line. To have an overview of all possible options, check out Red Hat's documentation or the Kernel documentation . With Docker, the story is similar: just use --lxc-conf from the command line to set LXC's options. Limit disk usage Something that LXC cannot do is limiting mass storage usage. Luckily, LXC integrates nicely with LVM (and brtfs, and zfs, and overlayfs), and you can use that for easily limiting disk usage. You can, for example, create a logical volume for each of your guests, and give that volume a limited size, so that space usage inside a guest cannot grow indefinitely. The same holds for Docker . Pay attention at /dev/random Processes inside LXC guests , by default, can read from /dev/random and can consume the entropy of the host . This may cause troubles if you need big amounts of randomness (to generate keys or whatever). If this is something that you don't want, then configure LXC so that it denies access to the character devices 1:8 (random) and 1:9 (urandom). Denying access to the path /dev/random is not enough, as mknod is allowed inside guests. Note however that doing so may break many applications inside the LXC guest that need randomness. Maybe consider using a different machine for processes that require randomness for security purposes. Use unprivileged containers Containers can be run from an unprivileged user . This means UID 0 of the guest can't match UID 0 of the host, and many potential security holes can't simply be exploited. Unfortunately, Docker has not support for unprivileged containers yet. However, if Docker is not a requirement and you can do well with LXC, start experimenting with unprivileged containers and consider using them in production. Programs like Apache will complain that it's unable to change its ulimit (because setting the ulimit is a privilege of the real root user). If you need to run programs that require special privileges, either configure them so that they do not complain, or consider using capabilities (but do not abuse them, and be cautious, or you risk introducing more problems than the ones your are trying to solve!) Conclusion LXC, Docker and the entire ecosystem around them can be considered quite mature and stable. They're surely production ready, and, if the right configuration is put in place, it can be pretty difficult to cause troubles to the host. However, whether they can be considered secure or not is up to you: what are you using containers for? Who are you giving access to? What privileges are you giving, what actions are you restricting? Always remember what LXC and Docker do by default, and what they do not do, especially when you use them to run untrusted code. Those that I have listed may only be a few of the problems that LXC, Docker and friends may expose. Remember to carefully review your configuration before opening the doors to others. Further reading If you liked this article, you'll find these ones interesting too: Containers & Docker: how secure are they? , from the Docker blog. Stéphane Graber's Security features from his LXC 1.0: Blog post series .","title":"Are LXC and Docker secure?"},{"tags":"fun","url":"http://andrea.corbellini.name/2015/02/15/prime-numbers-and-universe-factories/","text":"I'm a XKCD fan, and I look it up regularly. There's a comic that I particularly enjoyed: Pi Equals . The comic Pi Equals , from XKCD.com (CC-BY-NC 2.5). Well, it appears that Randall was right in that there's a help message hidden somewhere. And I just found it in a prime number: 245178888024581899558766786108789912235672909204719666025638877624752119760547413887830514281649480308707369249 That number corresponds to the ASCII encoding of this message: help!! i'm trapped in a universe factory!!!!!! Apparently, universe factory workers speak English and write ASCII. Nice coincidence, huh? The discovery Yesterday I was playing with the two illegal primes listed on Wikipedia. I was already aware of them, but I had never decoded them till yesterday. While doing so I wondered: how many prime numbers can be directly mapped to an executable file? Also, how many prime numbers can be directly mapped to plain English texts? Perhaps, while digging prime numbers, could we find something like the Iliad or a fully working operating system? Well, while asking myself those highly philosophical questions, Randall's comic quickly came to my mind, and I decided to start looking for help requests hidden in primes. You can't imagine how many of them I found! At first I tried looking for all prime numbers corresponding to strings starting with HELP! I'M TRAPPED IN A UNIVERSE FACTORY! , with an arbitrary suffix. I found many of them, but I wasn't satisfied with the result: I wanted something that was purely English/ASCII, without any garbage. Therefore I tried appending hashtags like #help or #universe , but could not find any interesting combination that was also a prime number (apparently, use of Twitter is forbidden inside universe factories). So I decided to change approach: I looked for all primes corresponding to HELP , followed by a variable number of exclamation marks, followed by I'M TRAPPED IN A UNIVERSE FACTORY , followed by other exclamation marks. I could not find anything. But then I tried with a lower case string, and... I found lots of such primes! help i'm trapped in a universe factory!!!!!!! help! i'm trapped in a universe factory!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! help!! i'm trapped in a universe factory!!!!!! help!!! i'm trapped in a universe factory!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! help!!!!!! i'm trapped in a universe factory!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! help!!!!!!!!! i'm trapped in a universe factory!!!! help!!!!!!!!!! i'm trapped in a universe factory!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! help!!!!!!!!!!!!! i'm trapped in a universe factory! help!!!!!!!!!!!!!!! i'm trapped in a universe factory!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! help!!!!!!!!!!!!!!!! i'm trapped in a universe factory!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! help!!!!!!!!!!!!!!!!! i'm trapped in a universe factory!!!!!!!!!! help!!!!!!!!!!!!!!!!!!! i'm trapped in a universe factory!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! help!!!!!!!!!!!!!!!!!!!! i'm trapped in a universe factory!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! help!!!!!!!!!!!!!!!!!!!!! i'm trapped in a universe factory!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! help!!!!!!!!!!!!!!!!!!!!!! i'm trapped in a universe factory!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! help!!!!!!!!!!!!!!!!!!!!!!!!! i'm trapped in a universe factory!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! help!!!!!!!!!!!!!!!!!!!!!!!!!! i'm trapped in a universe factory!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! help!!!!!!!!!!!!!!!!!!!!!!!!!!! i'm trapped in a universe factory!!!!!!! ... I picked the one I liked most and verified its primality with Wolfram|Alpha and numberempire.com . I'm not 100% sure that all the others are primes, as I used Fermat primality test . However I'm impressed by what I found. Now I can't stop wondering how much literature, physics or technology could be hidden in prime numbers, in plain English and UTF-8 encoded. :D (Obviously, I'm perfectly conscious on what's happening here, but I though this was a nice fact to share. It could also be a nice number to print on a shirt.) Dear universe factory worker, I'm going to rescue you, sooner or later. Just tell me how.","title":"Prime numbers and universe factories"},{"tags":"misc","url":"http://andrea.corbellini.name/2015/02/15/new-blog-again/","text":"This must be the third blog I start from scratch. But this time, I'm taking a serious commitment: I'm going to write here regularly. Wish me luck!","title":"New blog, again"}]}